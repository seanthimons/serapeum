---
phase: 19-conclusion-synthesis
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - migrations/007_add_section_hint.sql
  - R/pdf.R
  - R/db.R
  - R/rag.R
  - R/mod_document_notebook.R
autonomous: true
user_setup: []

must_haves:
  truths:
    - "PDF chunks receive section_hint metadata during ingestion"
    - "Existing databases gain section_hint column via migration"
    - "Conclusion synthesis retrieves section-targeted chunks for document notebooks"
    - "Synthesis prompt uses OWASP-compliant instruction-data separation"
    - "Synthesis cost is logged to cost_log table"
  artifacts:
    - path: "migrations/007_add_section_hint.sql"
      provides: "Database migration adding section_hint VARCHAR column to chunks table"
      contains: "ALTER TABLE chunks ADD COLUMN section_hint"
    - path: "R/pdf.R"
      provides: "detect_section_hint function with keyword heuristics + page position"
      exports: ["detect_section_hint"]
    - path: "R/rag.R"
      provides: "generate_conclusions_preset function with section-filtered RAG"
      exports: ["generate_conclusions_preset"]
  key_links:
    - from: "R/pdf.R"
      to: "R/db.R"
      via: "detect_section_hint called during chunk creation in process_pdf flow"
      pattern: "detect_section_hint"
    - from: "R/rag.R"
      to: "R/db.R"
      via: "search_chunks_hybrid with section_filter parameter"
      pattern: "section_filter"
---

<objective>
Add section metadata infrastructure to chunks and create the conclusion synthesis backend function.

Purpose: Enable section-targeted RAG retrieval so conclusion synthesis can focus on conclusion/limitations/future work sections of papers, improving synthesis relevance. The backend function will be consumed by UI preset buttons in Plan 02.

Output: DB migration for section_hint, detect_section_hint() in pdf.R, updated chunk creation flow, generate_conclusions_preset() in rag.R with OWASP-compliant prompts.
</objective>

<execution_context>
@C:/Users/sxthi/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/sxthi/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/19-conclusion-synthesis/19-RESEARCH.md

@R/pdf.R
@R/db.R
@R/rag.R
@R/db_migrations.R
@R/_ragnar.R
@R/mod_document_notebook.R
@migrations/006_create_citation_networks.sql
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add section_hint column and detection heuristics</name>
  <files>
    migrations/007_add_section_hint.sql
    R/pdf.R
    R/db.R
    R/mod_document_notebook.R
  </files>
  <action>
1. Create migration file `migrations/007_add_section_hint.sql`:
   - `ALTER TABLE chunks ADD COLUMN IF NOT EXISTS section_hint VARCHAR DEFAULT 'general';`
   - Follow the pattern from existing migrations (e.g., 005_add_doi_column.sql)

2. In `R/pdf.R`, add `detect_section_hint(text, page_number, total_pages)` function BEFORE `process_pdf`:
   - Use keyword heuristics with `grepl()` and `\\b` word boundaries (case-insensitive via `tolower()`)
   - Section mappings (check in this order, return first match):
     - "conclusion" -> grepl("\\b(conclusion|concluding remarks|summary and conclusion)\\b")
     - "limitations" -> grepl("\\b(limitation|constraint|caveat)\\b")
     - "future_work" -> grepl("\\b(future work|future research|future direction|further research|open question|open problem)\\b")
     - "discussion" -> grepl("\\b(discussion|interpretation|implication)\\b")
     - "introduction" -> grepl("\\b(introduction|background)\\b")
     - "methods" -> grepl("\\b(method|methodology|approach|experimental setup)\\b")
     - "results" -> grepl("\\b(result|finding|experiment)\\b")
   - Page position fallback: if page_number / total_pages > 0.8, return "late_section"
   - Default: return "general"
   - NOTE: The heuristic matches on the chunk TEXT content, not headings. It detects which section a chunk likely belongs to based on keywords IN the chunk.

3. In `R/pdf.R`, update the `process_pdf` function:
   - In the ragnar chunking branch (lines ~99-106): After ragnar returns chunks, add section_hint column by applying `detect_section_hint()` to each chunk's content, page_number, and total page_count
   - In the fallback word-based branch (lines ~130-136): Add `section_hint = detect_section_hint(chunk, page_num, extracted$page_count)` to the data.frame being rbind'd

4. In `R/db.R`, update `create_chunk` function (around line 355):
   - Add `section_hint = "general"` parameter with default
   - Add section_hint to the INSERT statement: `INSERT INTO chunks (id, source_id, source_type, chunk_index, content, page_number, section_hint) VALUES (?, ?, ?, ?, ?, ?, ?)`
   - Add section_hint to the parameter list

5. In `R/mod_document_notebook.R`, update the chunk creation call (around line 220 where `create_chunk` is called during PDF upload):
   - Pass the section_hint from the processed chunk data: `section_hint = chunk$section_hint` (or "general" if not present)
   - The process_pdf function now returns chunks with section_hint column, so this value is available

Do NOT modify the chunks table in `init_schema` — the migration file handles adding the column to existing databases, and new databases get the column from the migration system.
  </action>
  <verify>
    - `"C:\Program Files\R\R-4.5.1\bin\Rscript.exe" -e "source('R/pdf.R'); cat(detect_section_hint('This paper concludes that...', 10, 12))"` should print "conclusion"
    - `"C:\Program Files\R\R-4.5.1\bin\Rscript.exe" -e "source('R/pdf.R'); cat(detect_section_hint('Future research should explore...', 5, 12))"` should print "future_work"
    - `"C:\Program Files\R\R-4.5.1\bin\Rscript.exe" -e "source('R/pdf.R'); cat(detect_section_hint('We collected samples from...', 3, 12))"` should print "methods"
    - `"C:\Program Files\R\R-4.5.1\bin\Rscript.exe" -e "source('R/pdf.R'); cat(detect_section_hint('Some generic text here', 11, 12))"` should print "late_section"
    - `"C:\Program Files\R\R-4.5.1\bin\Rscript.exe" -e "source('R/pdf.R'); cat(detect_section_hint('Some generic text here', 3, 12))"` should print "general"
    - Migration file `migrations/007_add_section_hint.sql` exists and contains ALTER TABLE statement
  </verify>
  <done>
    - detect_section_hint() correctly classifies chunks by keyword heuristics and page position
    - process_pdf() returns chunks with section_hint column populated
    - create_chunk() accepts and stores section_hint in database
    - Migration 007 adds section_hint column to existing chunks tables
  </done>
</task>

<task type="auto">
  <name>Task 2: Create conclusion synthesis backend with section-filtered retrieval</name>
  <files>
    R/rag.R
    R/db.R
  </files>
  <action>
1. In `R/db.R`, update `search_chunks_hybrid` function (line 829) to accept optional `section_filter` parameter:
   - Add parameter: `section_filter = NULL` after `limit`
   - This parameter is a character vector like `c("conclusion", "future_work", "limitations", "discussion", "late_section")`
   - For the ragnar search path: After ragnar returns results and notebook filtering is done, if section_filter is not NULL, do a secondary filter. Look up the section_hint for each chunk by querying the chunks table using the content/origin. If ragnar results don't have section_hint, query from chunks table using source matching. If no section_hint data found (pre-migration chunks), keep all results (graceful degradation).
   - IMPORTANT: Ragnar results may not have section_hint column. The simplest approach: after ragnar returns results, if section_filter is provided, do a JOIN query against the chunks table to get section_hints for the matching content, then filter. If chunk has no section_hint (NULL or missing), treat as "general" and include it only if section_filter is NULL.
   - For the legacy search path (the SQL queries around lines 461-480): Add a WHERE clause `AND c.section_hint IN (...)` when section_filter is provided. Use parameterized query or sprintf with the filter values.

2. In `R/rag.R`, add `generate_conclusions_preset` function after `generate_preset`:
   - Signature: `generate_conclusions_preset(con, config, notebook_id, notebook_type = "document", session_id = NULL)`
   - Extract api_key, chat_model from config (same pattern as generate_preset)
   - Check api_key is set (same pattern)
   - Get notebook with get_notebook(con, notebook_id)
   - For document notebooks (notebook_type == "document"):
     - Use `search_chunks_hybrid(con, query = "conclusions limitations future work research gaps directions", notebook_id = notebook_id, limit = 10, section_filter = c("conclusion", "limitations", "future_work", "discussion", "late_section"))`
     - If no results returned with section_filter, retry WITHOUT section_filter (graceful fallback for pre-migration data)
   - For search notebooks (notebook_type == "search"):
     - Use `search_chunks_hybrid(con, query = "conclusions limitations future work research gaps", notebook_id = notebook_id, limit = 10)` — NO section_filter (abstracts don't have section structure)
   - Build context with `build_context(chunks)`
   - System prompt (OWASP LLM01:2025 compliant — instructions BEFORE data, clear delimiters):
     ```
     You are a research synthesis assistant. Your task is to:
     1. Summarize the key conclusions across the provided research sources
     2. Identify common themes, agreements, and divergent positions
     3. Propose future research directions based on identified gaps and limitations

     IMPORTANT: Base your synthesis ONLY on the provided sources. Do not invent findings or cite sources not provided. If sources conflict, note the disagreement explicitly.

     OUTPUT FORMAT:
     ## Research Conclusions
     [Synthesized conclusions with citations using [Source Name] format]

     ## Agreements & Disagreements
     [Where sources agree and diverge]

     ## Research Gaps & Future Directions
     [Proposed directions based on limitations and gaps identified in the sources]
     ```
   - User prompt with OWASP instruction-data separation:
     ```
     ===== BEGIN RESEARCH SOURCES =====
     {context}
     ===== END RESEARCH SOURCES =====

     Synthesize the conclusions and future research directions from the sources above.
     ```
   - Call chat_completion with format_chat_messages(system_prompt, user_prompt)
   - Log cost with log_cost() if session_id provided (follow existing pattern from rag_query)
   - Return result$content
   - Wrap in tryCatch, return error message on failure

3. The function returns plain markdown text. The AI disclaimer will be added by the UI layer (Plan 02), NOT in this function. This keeps the backend clean and reusable.
  </action>
  <verify>
    - `"C:\Program Files\R\R-4.5.1\bin\Rscript.exe" -e "source('R/rag.R'); cat(exists('generate_conclusions_preset'))"` should print TRUE
    - Verify function signature includes notebook_type and session_id parameters
    - Verify search_chunks_hybrid in db.R now has section_filter parameter in its signature
    - grep for "BEGIN RESEARCH SOURCES" in R/rag.R confirms OWASP delimiters are present
    - grep for "log_cost" in the generate_conclusions_preset function confirms cost logging
  </verify>
  <done>
    - generate_conclusions_preset() exists in R/rag.R with section-filtered retrieval for document notebooks
    - search_chunks_hybrid() accepts section_filter parameter
    - OWASP-compliant instruction-data separation in synthesis prompt
    - Graceful fallback when section_hint data not available (pre-migration chunks)
    - Cost logging integrated via log_cost()
    - Search notebooks use generic retrieval (no section filter) as designed
  </done>
</task>

</tasks>

<verification>
- Migration 007 file exists with correct ALTER TABLE syntax
- detect_section_hint() classifies at least 5 distinct section types correctly
- process_pdf() output includes section_hint column
- create_chunk() stores section_hint in database
- search_chunks_hybrid() can filter by section_hint
- generate_conclusions_preset() works for both document and search notebook types
- OWASP delimiters present in synthesis prompt
- Cost logging wired up
</verification>

<success_criteria>
- Section metadata pipeline complete: ingestion -> storage -> retrieval
- Conclusion synthesis function callable from both notebook types
- All synthesis prompts use instruction-data separation (OWASP LLM01:2025)
- Graceful degradation for databases without section_hint data
</success_criteria>

<output>
After completion, create `.planning/phases/19-conclusion-synthesis/19-01-SUMMARY.md`
</output>
