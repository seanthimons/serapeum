---
phase: 22-module-migration
plan: 03
type: execute
wave: 2
depends_on: ["22-01"]
files_modified:
  - R/mod_search_notebook.R
autonomous: true

must_haves:
  truths:
    - "Search notebook embed handler writes to per-notebook ragnar store, not shared store"
    - "User removes paper from search results and its chunks are deleted from ragnar store"
    - "Search notebook with embedded abstracts but no per-notebook store shows migration prompt"
    - "After embedding, chunks table rows have 'ragnar_indexed' sentinel in embedding column"
    - "Incremental embedding appends to existing store without rebuild"
    - "Empty search notebook does not show migration prompt"
  artifacts:
    - path: "R/mod_search_notebook.R"
      provides: "Per-notebook store wiring for embed, chunk deletion on paper remove, migration prompt"
      contains: "ensure_ragnar_store"
  key_links:
    - from: "R/mod_search_notebook.R"
      to: "R/_ragnar.R"
      via: "ensure_ragnar_store, delete_abstract_chunks_from_ragnar, mark_as_ragnar_indexed, get_notebook_ragnar_path"
      pattern: "delete_abstract_chunks_from_ragnar|ensure_ragnar_store"
---

<objective>
Migrate search notebook module to use per-notebook ragnar stores: rewire embed handler, add chunk deletion on paper removal, add migration prompt for existing notebooks, mark embedded chunks with sentinel value.

Purpose: Search notebooks achieve per-notebook isolation. Embedding, retrieval, and paper removal all operate on the per-notebook store. Incremental embedding appends without rebuild.

Output: Updated mod_search_notebook.R with full per-notebook store wiring.
</objective>

<execution_context>
@C:/Users/sxthi/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/sxthi/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/22-module-migration/22-RESEARCH.md
@.planning/phases/22-module-migration/22-01-SUMMARY.md
@.planning/phases/21-store-lifecycle/21-02-SUMMARY.md

Key references:
- R/mod_search_notebook.R lines 1671-1780: Embed handler (currently uses shared store via get_ragnar_store)
- R/mod_search_notebook.R lines 1715-1720: Shared store path construction
- R/mod_search_notebook.R lines 582-604: papers_need_embedding reactive (checks chunks.embedding IS NOT NULL)
- R/mod_search_notebook.R lines 609-636: embed_button renderUI
- R/mod_search_notebook.R lines 695-718: Paper delete handler (adds to exclusion list, deletes from DB)
- R/_ragnar.R: ensure_ragnar_store(), delete_abstract_chunks_from_ragnar(), mark_as_ragnar_indexed(), get_notebook_ragnar_path()
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add migration detection and rag_ready state to search notebook</name>
  <files>R/mod_search_notebook.R</files>
  <action>
Add per-notebook store migration support to `mod_search_notebook.R`:

**1. Add reactive state variables** (in the module server function, near the top where other reactiveVals are declared):
```r
# Phase 22: Per-notebook store migration state
rag_ready <- reactiveVal(TRUE)
store_healthy <- reactiveVal(NULL)
```

**2. Add notebook-open migration check** (as a new observeEvent on notebook_id):

Add near the beginning of the server function. This mirrors the document notebook pattern but checks abstracts instead of documents:

```r
# Phase 22: Check for per-notebook store migration on notebook open
observeEvent(notebook_id(), {
  nb_id <- notebook_id()
  req(nb_id)

  # Reset state
  rag_ready(TRUE)
  store_healthy(NULL)

  store_path <- get_notebook_ragnar_path(nb_id)

  # Check if notebook has embedded content but no per-notebook store
  has_content <- tryCatch({
    abstracts <- DBI::dbGetQuery(con(), "
      SELECT COUNT(*) as cnt FROM abstracts WHERE notebook_id = ?
    ", list(nb_id))
    abstracts$cnt[1] > 0
  }, error = function(e) FALSE)

  if (has_content && !file.exists(store_path)) {
    # Has abstracts but no per-notebook store — needs migration
    rag_ready(FALSE)
    showModal(modalDialog(
      title = "Search Index Setup Required",
      tags$p("This notebook has papers but no search index. Synthesis and chat features will be unavailable until you re-index."),
      footer = tagList(
        actionButton(ns("reindex_search_nb"), "Re-index Now", class = "btn-primary"),
        modalButton("Later")
      ),
      easyClose = FALSE
    ))
  } else if (file.exists(store_path)) {
    # Store exists — check integrity
    result <- check_store_integrity(store_path)
    store_healthy(result$ok)
    rag_ready(result$ok)
    if (!result$ok) {
      showModal(modalDialog(
        title = "Search Index Needs Rebuild",
        tags$p("The search index for this notebook appears to be corrupted."),
        tags$p(class = "text-muted small", paste("Error:", result$error)),
        footer = tagList(
          actionButton(ns("rebuild_search_index"), "Rebuild Index", class = "btn-primary"),
          modalButton("Later")
        ),
        easyClose = FALSE
      ))
    }
  } else {
    # No content, no store — fine, lazy creation later
    store_healthy(TRUE)
    rag_ready(TRUE)
  }
})
```

**3. Add re-index handler for search notebooks:**

```r
observeEvent(input$reindex_search_nb, {
  removeModal()
  nb_id <- notebook_id()
  req(nb_id)

  cfg <- config()
  api_key <- get_setting(cfg, "openrouter", "api_key")
  embed_model <- get_setting(cfg, "defaults", "embedding_model") %||% "openai/text-embedding-3-small"

  withProgress(message = "Re-indexing search notebook...", value = 0, {
    result <- rebuild_notebook_store(
      notebook_id = nb_id,
      con = con(),
      api_key = api_key,
      embed_model = embed_model,
      progress_callback = function(count, total) {
        incProgress(1/total, detail = paste0("Embedding item ", count, " of ", total))
      }
    )
  })

  if (result$success) {
    rag_ready(TRUE)
    store_healthy(TRUE)
    # Mark all abstract chunks as ragnar-indexed
    tryCatch({
      abstract_ids <- DBI::dbGetQuery(con(), "SELECT id FROM abstracts WHERE notebook_id = ?", list(nb_id))$id
      mark_as_ragnar_indexed(con(), abstract_ids, source_type = "abstract")
    }, error = function(e) message("[ragnar] Sentinel update failed: ", e$message))
    showNotification(paste("Re-indexed", result$count, "items successfully."), type = "message", duration = 5)
  } else {
    rag_ready(FALSE)
    store_healthy(FALSE)
    showNotification(paste("Re-indexing failed:", result$error), type = "error", duration = NULL)
  }
})

# Rebuild handler for corruption recovery (same pattern as document notebook)
observeEvent(input$rebuild_search_index, {
  removeModal()
  nb_id <- notebook_id()
  req(nb_id)

  cfg <- config()
  api_key <- get_setting(cfg, "openrouter", "api_key")
  embed_model <- get_setting(cfg, "defaults", "embedding_model") %||% "openai/text-embedding-3-small"

  withProgress(message = "Rebuilding search index...", value = 0, {
    result <- rebuild_notebook_store(
      notebook_id = nb_id,
      con = con(),
      api_key = api_key,
      embed_model = embed_model,
      progress_callback = function(count, total) {
        incProgress(1/total, detail = paste0("Re-embedding ", count, " of ", total))
      }
    )
  })

  if (result$success) {
    store_healthy(TRUE)
    rag_ready(TRUE)
    showNotification(paste("Index rebuilt.", result$count, "items re-embedded."), type = "message")
  } else {
    store_healthy(FALSE)
    showNotification(paste("Rebuild failed:", result$error), type = "error", duration = NULL)
  }
})
```

**4. Conditionally disable embed button when rag_ready is FALSE:**

In the existing `output$embed_button <- renderUI({...})` block (around lines 609-636), add at the top:
```r
# Disable embed if migration needed but no API key
if (!isTRUE(rag_ready()) && need_embed > 0) {
  return(tags$button(
    class = "btn btn-secondary w-100 mb-2",
    disabled = "disabled",
    title = "Re-index this notebook to enable embedding",
    "Embedding unavailable"
  ))
}
```
Place this AFTER the `need_embed <- papers_need_embedding()` line but BEFORE the existing conditional logic.

Actually, looking at the research more carefully — the embed button should still work after migration because embedding IS the re-indexing for new papers. The disable should only apply to the chat/synthesis features. Leave the embed button as-is. Instead, just ensure the embed handler uses per-notebook store (Task 2).
  </action>
  <verify>
Run: `"C:\Program Files\R\R-4.5.1\bin\Rscript.exe" -e "parse('R/mod_search_notebook.R'); cat('mod_search_notebook.R parses OK\n')"`
Grep for "rag_ready" in R/mod_search_notebook.R — should find declaration and usage.
Grep for "reindex_search_nb" in R/mod_search_notebook.R — should find input binding and handler.
Grep for "store_healthy" in R/mod_search_notebook.R — should find declaration and usage.
  </verify>
  <done>Search notebook module detects migration need and shows re-index prompt. rag_ready and store_healthy states track availability. Rebuild handler recovers from corruption.</done>
</task>

<task type="auto">
  <name>Task 2: Rewire embed handler to per-notebook store and add chunk deletion on paper removal</name>
  <files>R/mod_search_notebook.R</files>
  <action>
**Part A: Rewire the embed handler (lines 1671-1780)**

In the `observeEvent(input$embed_papers, {...})` handler:

1. Replace the shared store path construction (lines 1715-1720):
```r
# OLD (remove):
ragnar_store_path <- file.path(
  dirname(get_setting(cfg, "app", "db_path") %||% "data/notebooks.duckdb"),
  "serapeum.ragnar.duckdb")
store <- get_ragnar_store(ragnar_store_path,
                          openrouter_api_key = api_key_or,
                          embed_model = embed_model)
```

With per-notebook store:
```r
# Phase 22: Use per-notebook ragnar store
store <- tryCatch(
  ensure_ragnar_store(nb_id, session, api_key_or, embed_model),
  error = function(e) {
    message("[ragnar] Failed to open per-notebook store: ", e$message)
    store_healthy(FALSE)
    NULL
  }
)
```

2. Keep the `ragnar_available()` check on line 1702 as-is (will be removed in Phase 23).

3. After `build_ragnar_index(store)` succeeds and `ragnar_indexed <- TRUE` (around line 1738), add sentinel marking:
```r
# Mark embedded abstracts in chunks table (sentinel for "needs embedding" detection)
tryCatch({
  mark_as_ragnar_indexed(con(), paper_ids, source_type = "abstract")
}, error = function(e) message("[ragnar] Sentinel marking failed: ", e$message))

# Update rag state
rag_ready(TRUE)
store_healthy(TRUE)
```

4. Update the origin encoding in the abstract chunk data.frame (line 1729). Currently it uses:
```r
origin = paste0("abstract:", abs_row$id)
```
This is already correct for the `delete_abstract_chunks_from_ragnar` function which matches by `abstract:{id}` prefix. Keep it as-is. However, to support section_hint metadata for future filtering, enhance it to use `encode_origin_metadata`:
```r
origin = encode_origin_metadata(
  paste0("abstract:", abs_row$id),
  section_hint = "general",
  doi = NULL,
  source_type = "abstract"
)
```
This produces: `"abstract:{id}|section=general|type=abstract"` — enabling future section filtering. The delete function uses LIKE prefix matching so `abstract:{id}%` will still match.

**Part B: Add chunk deletion on paper removal**

In the paper delete handler (around lines 695-718), after `delete_abstract(con(), paper$id)` (line 712), add:

```r
# Phase 22: Delete chunks from per-notebook ragnar store
tryCatch({
  delete_abstract_chunks_from_ragnar(notebook_id(), paper$id)
}, error = function(e) {
  message("[ragnar] Failed to delete chunks for removed paper: ", e$message)
})
```

This should be placed AFTER the `delete_abstract()` call but BEFORE `paper_refresh(paper_refresh() + 1)`.

**Part C: Update papers_need_embedding reactive** (lines 582-604)

The current check queries `chunks.embedding IS NOT NULL`. After Phase 22, embedded papers have `embedding = 'ragnar_indexed'` (not NULL). This check already works correctly because `'ragnar_indexed' IS NOT NULL` evaluates to TRUE — so papers with the sentinel will correctly NOT appear in the "needs embedding" count. No change needed.

However, verify this by reading the exact query. The query at line 596-602 counts chunks where `embedding IS NOT NULL`. Papers with `'ragnar_indexed'` sentinel will have `embedding IS NOT NULL` = TRUE, so they'll be counted as embedded. Correct.
  </action>
  <verify>
Run: `"C:\Program Files\R\R-4.5.1\bin\Rscript.exe" -e "parse('R/mod_search_notebook.R'); cat('mod_search_notebook.R parses OK\n')"`
Grep for "serapeum.ragnar.duckdb" in R/mod_search_notebook.R — should return zero results.
Grep for "ensure_ragnar_store" in R/mod_search_notebook.R — should find call in embed handler.
Grep for "delete_abstract_chunks_from_ragnar" in R/mod_search_notebook.R — should find call in delete handler.
Grep for "mark_as_ragnar_indexed" in R/mod_search_notebook.R — should find call after embed.
Grep for "encode_origin_metadata" in R/mod_search_notebook.R — should find call in chunk data.frame.
  </verify>
  <done>Search notebook embed handler uses per-notebook store. Paper removal deletes chunks from ragnar. Sentinel marking tracks embedding status. Origin encoding includes section metadata. No shared store references remain.</done>
</task>

</tasks>

<verification>
1. R/mod_search_notebook.R parses without errors
2. No "serapeum.ragnar.duckdb" references remain
3. Embed handler uses ensure_ragnar_store() for per-notebook store
4. Paper deletion triggers delete_abstract_chunks_from_ragnar()
5. After embedding, mark_as_ragnar_indexed() sets sentinel values
6. Origin encoding uses encode_origin_metadata for section_hint support
</verification>

<success_criteria>
- Embedding writes to per-notebook ragnar store (data/ragnar/{notebook_id}.duckdb)
- Removing paper from search results deletes its chunks from ragnar store
- Migration prompt shows for search notebooks with content but no per-notebook store
- Incremental embedding appends to existing store
- papers_need_embedding count correctly identifies unembedded papers
</success_criteria>

<output>
After completion, create `.planning/phases/22-module-migration/22-03-SUMMARY.md`
</output>
