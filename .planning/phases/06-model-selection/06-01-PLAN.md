---
phase: 06-model-selection
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - R/api_openrouter.R
  - R/cost_tracking.R
  - R/mod_settings.R
autonomous: true

must_haves:
  truths:
    - "User can select from 10+ chat models in settings"
    - "User sees context window and pricing for each model in the dropdown"
    - "User sees detailed model info (provider, pricing per M tokens, context window) for the currently selected model"
    - "User can switch models and the new model is used for subsequent chat/query operations"
    - "Cost estimation uses live pricing when available instead of only hardcoded table"
  artifacts:
    - path: "R/api_openrouter.R"
      provides: "list_chat_models() and get_default_chat_models() functions"
      contains: "list_chat_models"
    - path: "R/cost_tracking.R"
      provides: "Dynamic pricing cache updated from API responses"
      contains: "update_model_pricing"
    - path: "R/mod_settings.R"
      provides: "Dynamic chat model selector with model info panel"
      contains: "model_info"
  key_links:
    - from: "R/mod_settings.R"
      to: "R/api_openrouter.R"
      via: "list_chat_models() call"
      pattern: "list_chat_models"
    - from: "R/mod_settings.R"
      to: "R/cost_tracking.R"
      via: "update_model_pricing() on model list fetch"
      pattern: "update_model_pricing"
---

<objective>
Implement dynamic model selection with pricing and capability visibility in Serapeum settings.

Purpose: Users currently choose from a hardcoded list of 9 chat models with no pricing or context window info. This plan fetches available models from OpenRouter's API (like embedding models already do), displays pricing and context window in the selector, and shows detailed model info for the selected model.

Output: Dynamic chat model dropdown with 10+ models, model info panel in settings, and live pricing integration with cost tracking.
</objective>

<execution_context>
@C:/Users/sxthi/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/sxthi/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@R/api_openrouter.R
@R/cost_tracking.R
@R/mod_settings.R
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add chat model listing API and dynamic pricing</name>
  <files>R/api_openrouter.R, R/cost_tracking.R</files>
  <action>
**In R/api_openrouter.R:**

1. Create `get_default_chat_models()` function returning a data frame with columns: `id`, `name`, `context_length`, `prompt_price`, `completion_price`, `tier` (budget/mid/premium). Include at least these 10+ models as hardcoded fallback:
   - Budget: deepseek/deepseek-chat, google/gemini-2.0-flash-001, openai/gpt-4o-mini
   - Mid: moonshotai/kimi-k2-0905, anthropic/claude-3-5-haiku, meta-llama/llama-3.3-70b-instruct, google/gemini-2.5-flash-preview-05-20
   - Premium: anthropic/claude-sonnet-4, openai/gpt-4o, google/gemini-2.5-pro-preview
   Use known pricing from OpenRouter for default values. Context lengths from known specs.

2. Create `list_chat_models(api_key)` function that:
   - Calls OpenRouter `/api/v1/models` endpoint (reuse `build_openrouter_request`)
   - Filters to text-generation models by checking `x$architecture$modality` contains "text" and does NOT contain "embed"
   - Also filters OUT models where `x$id` contains "embed" (safety net)
   - Extracts: `id`, `name`, `context_length` (from `x$context_length`), `prompt_price` (from `as.numeric(x$pricing$prompt) * 1000000`), `completion_price` (from `as.numeric(x$pricing$completion) * 1000000`)
   - Assigns tier based on prompt_price: budget (<0.50), mid (0.50-2.00), premium (>2.00)
   - Filters to a curated set of well-known providers: openai, anthropic, google, meta-llama, deepseek, moonshotai, mistralai, qwen, cohere (to avoid showing 500+ obscure models)
   - Sorts by tier then name
   - Falls back to `get_default_chat_models()` on any error (same pattern as `list_embedding_models`)
   - Returns data frame with same columns as `get_default_chat_models()`

3. Create `format_chat_model_choices(models_df)` helper that returns a named character vector suitable for selectizeInput:
   - Names formatted as: "[Tier Icon] ModelName (ctx: Xk, $Y.YY/M in, $Z.ZZ/M out)"
   - Tier icons: budget="$", mid="$$", premium="$$$"
   - Context length formatted as "128k", "200k", etc. (divide by 1000)
   - Values are model IDs

**In R/cost_tracking.R:**

4. Add `update_model_pricing(models_df)` function that takes the data frame from `list_chat_models()` and updates the `MODEL_PRICING` list in the package environment. For each row in models_df, set `MODEL_PRICING[[row$id]] <- list(prompt = row$prompt_price, completion = row$completion_price)`. This ensures `estimate_cost()` uses live pricing for any model the user selects.

5. Make `MODEL_PRICING` mutable by storing it in a local environment instead of as a top-level list assignment. Create a `pricing_env` environment at module level, move MODEL_PRICING into it, and update `estimate_cost()` to read from `pricing_env$MODEL_PRICING`. The `update_model_pricing()` function writes to the same environment.
  </action>
  <verify>
Run `"C:\Program Files\R\R-4.5.1\bin\Rscript.exe" -e "source('R/api_openrouter.R'); source('R/cost_tracking.R'); cat('Default models:', nrow(get_default_chat_models()), '\n'); cat('Pricing env works:', exists('pricing_env'), '\n')"` -- should show 10+ default models and confirm pricing_env exists.
  </verify>
  <done>
- `get_default_chat_models()` returns 10+ models with id, name, context_length, prompt_price, completion_price, tier
- `list_chat_models(api_key)` fetches live models from OpenRouter, filters to chat models, falls back to defaults
- `format_chat_model_choices(df)` produces named vector with pricing/context info in labels
- `update_model_pricing(df)` updates the shared pricing table used by `estimate_cost()`
- `estimate_cost()` uses mutable pricing environment (backwards compatible)
  </done>
</task>

<task type="auto">
  <name>Task 2: Dynamic chat model selector and model info panel in settings UI</name>
  <files>R/mod_settings.R</files>
  <action>
**In R/mod_settings.R UI function (`mod_settings_ui`):**

1. Replace the hardcoded `selectInput(ns("chat_model"), ...)` (lines 50-65) with a `selectizeInput` (matching the embed_model pattern):
   ```r
   div(
     class = "d-flex align-items-end gap-2",
     div(
       style = "flex-grow: 1;",
       selectizeInput(ns("chat_model"), "Chat Model",
                      choices = format_chat_model_choices(get_default_chat_models()),
                      selected = "moonshotai/kimi-k2-0905")
     ),
     actionButton(ns("refresh_chat_models"), NULL,
                  icon = icon("refresh"),
                  class = "btn-outline-secondary btn-sm",
                  title = "Refresh model list",
                  style = "margin-bottom: 15px;")
   )
   ```

2. Remove the old static pricing hint paragraph (`p(class = "text-muted small mb-3", "Budget < $0.50/M tokens | ...")`).

3. Add a model info panel below the chat model selector:
   ```r
   uiOutput(ns("model_info"))
   ```
   This will show context window, pricing, and tier for the currently selected chat model.

**In R/mod_settings.R server function (`mod_settings_server`):**

4. Add a `refresh_chat_trigger` reactiveVal (same pattern as `refresh_embed_trigger`).

5. Create `update_chat_model_choices(api_key, current_selection = NULL)` helper function inside the server (same pattern as `update_embed_model_choices`):
   - Calls `list_chat_models(api_key)`, falls back to `get_default_chat_models()`
   - Stores the models data frame in a `chat_models_data` reactiveVal for use by the info panel
   - Calls `update_model_pricing(models_df)` to sync pricing with cost tracking
   - Calls `format_chat_model_choices()` to get display choices
   - Updates selectizeInput with new choices, preserving current selection if valid

6. Wire up the refresh button:
   ```r
   observeEvent(input$refresh_chat_models, {
     refresh_chat_trigger(refresh_chat_trigger() + 1)
     showNotification("Refreshing chat models...", type = "message", duration = 2)
   })
   ```

7. Wire up reactive refresh (on API key change or manual refresh) -- same pattern as embedding model refresh:
   ```r
   observe({
     api_key <- input$openrouter_key
     refresh_chat_trigger()
     current <- input$chat_model
     update_chat_model_choices(api_key, current)
   }) |> bindEvent(input$openrouter_key, refresh_chat_trigger(), ignoreInit = TRUE)
   ```

8. In the init observer (the `observe({ cfg <- config_rv(); ... }) |> bindEvent(config_rv(), once = TRUE)` block), update the chat model loading to use the new dynamic approach:
   - After getting `chat_model` from DB/config, call `update_chat_model_choices(or_key, chat_model)` instead of `updateSelectInput(session, "chat_model", selected = chat_model)`

9. Render model info panel showing details for the currently selected model:
   ```r
   output$model_info <- renderUI({
     req(input$chat_model)
     models <- chat_models_data()
     req(models)

     selected <- models[models$id == input$chat_model, ]
     if (nrow(selected) == 0) return(NULL)

     row <- selected[1, ]
     tier_badge <- switch(row$tier,
       "budget" = span(class = "badge bg-success", "Budget"),
       "mid" = span(class = "badge bg-primary", "Mid-tier"),
       "premium" = span(class = "badge bg-warning text-dark", "Premium"),
       span(class = "badge bg-secondary", row$tier)
     )

     ctx_display <- if (row$context_length >= 1000000) {
       sprintf("%.1fM tokens", row$context_length / 1000000)
     } else {
       sprintf("%sk tokens", format(round(row$context_length / 1000), big.mark = ","))
     }

     div(
       class = "card card-body bg-light py-2 px-3 mt-2 small",
       div(class = "d-flex justify-content-between align-items-center mb-1",
         span(class = "fw-semibold", row$name),
         tier_badge
       ),
       div(class = "text-muted",
         icon("window-maximize", class = "me-1"), "Context: ", ctx_display,
         span(class = "mx-2", "|"),
         icon("arrow-right-to-bracket", class = "me-1"),
         sprintf("$%.2f/M in", row$prompt_price),
         span(class = "mx-1", "/"),
         sprintf("$%.2f/M out", row$completion_price)
       )
     )
   })
   ```

10. Ensure the saved settings flow still works: the save observer already saves `input$chat_model` which will be a model ID string -- no changes needed there.
  </action>
  <verify>
Run `"C:\Program Files\R\R-4.5.1\bin\Rscript.exe" -e "source('R/api_openrouter.R'); source('R/cost_tracking.R'); source('R/db.R'); tryCatch(loadNamespace('shiny'), error = function(e) install.packages('shiny')); source('R/mod_settings.R'); cat('mod_settings_ui exists:', exists('mod_settings_ui'), '\n'); cat('mod_settings_server exists:', exists('mod_settings_server'), '\n')"` -- should confirm both functions exist and source without errors.
  </verify>
  <done>
- Chat model dropdown is dynamic (selectizeInput) with refresh button, matching embedding model pattern
- Dropdown labels show pricing and context window info for each model
- Model info panel below selector shows name, tier badge, context window, and per-million-token pricing for selected model
- Models refresh when API key changes or refresh button clicked
- Saved model selection persists across sessions
- Switching models does not break existing chat/query/embedding functionality
  </done>
</task>

</tasks>

<verification>
1. All three modified R files source without errors
2. `get_default_chat_models()` returns 10+ rows with all required columns
3. `format_chat_model_choices()` produces human-readable labels with pricing
4. `estimate_cost()` still works (backwards compatible)
5. App starts and settings page shows dynamic chat model dropdown
6. Selecting a model shows info panel with context window and pricing
7. Changing API key refreshes the model list
8. Saving settings and reloading preserves model selection
</verification>

<success_criteria>
- MODL-01: User can select from 10+ chat models with pricing and context window info visible in dropdown labels
- MODL-02: User sees model details (tier badge, context window, pricing per M tokens) in info panel below selector
- Phase success criteria 1-4 all met: 10+ models, pricing/context visible, model details shown, switching works
</success_criteria>

<output>
After completion, create `.planning/phases/06-model-selection/06-01-SUMMARY.md`
</output>
