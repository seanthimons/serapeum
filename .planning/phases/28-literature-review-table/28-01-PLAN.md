---
phase: 28-literature-review-table
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - R/db.R
  - R/mod_search_notebook.R
  - R/rag.R
  - R/mod_document_notebook.R
  - app.R
  - migrations/008_add_document_metadata.sql
autonomous: true

must_haves:
  truths:
    - "User sees a Lit Review button in the document notebook preset panel"
    - "User clicks Lit Review and receives a formatted GFM table with one row per paper and columns: Author/Year, Methodology, Sample, Key Findings, Limitations"
    - "Table renders with Bootstrap styling, horizontal scroll, and frozen first column in the chat panel"
    - "Author/Year column includes clickable DOI links for documents imported from search notebooks (injected server-side, not by LLM)"
    - "When the LLM produces malformed output, user sees plain text error message rather than garbled table"
    - "Papers imported from search notebook carry OpenAlex metadata (title, authors, year, DOI, abstract_id) into the documents table"
    - "User can export the table via existing chat export mechanism (Markdown or HTML)"
  artifacts:
    - path: "migrations/008_add_document_metadata.sql"
      provides: "Schema migration adding title, authors, year, doi, abstract_id to documents table"
      contains: "ALTER TABLE documents ADD COLUMN"
    - path: "R/db.R"
      provides: "Updated create_document() with optional metadata params"
      contains: "create_document"
    - path: "R/mod_search_notebook.R"
      provides: "Updated import workflow passing OpenAlex metadata to create_document()"
      contains: "create_document"
    - path: "R/rag.R"
      provides: "build_context_by_paper(), validate_gfm_table(), generate_lit_review_table() with DOI injection"
      contains: "generate_lit_review_table"
    - path: "R/mod_document_notebook.R"
      provides: "Lit Review button, handler, disclaimer check, HTML post-processing for scroll wrapper"
      contains: "btn_lit_review"
    - path: "app.R"
      provides: "CSS for scrollable table with frozen first column"
      contains: "lit-review-scroll"
  key_links:
    - from: "R/mod_document_notebook.R"
      to: "R/rag.R"
      via: "observeEvent calls generate_lit_review_table()"
      pattern: "generate_lit_review_table\\("
    - from: "R/mod_document_notebook.R"
      to: "chat message renderer"
      via: "preset_type = lit_review triggers AI disclaimer and scroll wrapper injection"
      pattern: "lit_review"
    - from: "R/rag.R"
      to: "R/db.R"
      via: "generate_lit_review_table queries documents table for metadata (title, authors, year, doi)"
      pattern: "SELECT.*title.*authors.*year.*doi.*FROM documents"
    - from: "R/mod_search_notebook.R"
      to: "R/db.R"
      via: "Import workflow passes OpenAlex metadata to create_document()"
      pattern: "create_document\\("
    - from: "migrations/008_add_document_metadata.sql"
      to: "R/db.R"
      via: "Migration adds columns that create_document() and list_documents() use"
      pattern: "title.*authors.*year.*doi.*abstract_id"
---

<objective>
Add a Literature Review Table synthesis preset to the document notebook that generates a structured per-paper comparison matrix with Author/Year (with DOI links), Methodology, Sample, Key Findings, and Limitations columns. This includes document metadata infrastructure (schema migration + import workflow update) to support server-side DOI injection.

Purpose: Researchers can generate a side-by-side comparison of all papers in their document notebook, with DOI-linked author citations for papers imported from search notebooks.
Output: Working Lit Review button in document notebook, migration for document metadata, updated import workflow, GFM table with Bootstrap styling and frozen first column.
</objective>

<execution_context>
@/home/sean/.claude/get-shit-done/workflows/execute-plan.md
@/home/sean/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@/home/sean/Documents/serapeum/.planning/PROJECT.md
@/home/sean/Documents/serapeum/.planning/ROADMAP.md
@/home/sean/Documents/serapeum/.planning/STATE.md
@/home/sean/Documents/serapeum/.planning/phases/28-literature-review-table/28-CONTEXT.md
@/home/sean/Documents/serapeum/.planning/phases/28-literature-review-table/28-RESEARCH.md
@/home/sean/Documents/serapeum/R/db.R
@/home/sean/Documents/serapeum/R/db_migrations.R
@/home/sean/Documents/serapeum/R/rag.R
@/home/sean/Documents/serapeum/R/mod_document_notebook.R
@/home/sean/Documents/serapeum/R/mod_search_notebook.R
@/home/sean/Documents/serapeum/R/utils_export.R
@/home/sean/Documents/serapeum/app.R
</context>

<tasks>

<task type="auto">
  <name>Task 1: Schema migration and create_document() update</name>
  <files>migrations/008_add_document_metadata.sql, R/db.R</files>
  <action>
**Migration file `migrations/008_add_document_metadata.sql`:**

Create a new SQL migration file adding five nullable columns to the documents table. Follow the exact pattern of existing migrations (e.g., `007_add_section_hint.sql`). Each ALTER TABLE must be a separate statement separated by semicolons:

```sql
-- Migration 008: Add metadata columns to documents table for DOI injection
-- Supports Literature Review Table (Phase 28)
ALTER TABLE documents ADD COLUMN title VARCHAR;
ALTER TABLE documents ADD COLUMN authors VARCHAR;
ALTER TABLE documents ADD COLUMN year INTEGER;
ALTER TABLE documents ADD COLUMN doi VARCHAR;
ALTER TABLE documents ADD COLUMN abstract_id VARCHAR;
```

All columns are nullable for backward compatibility. `authors` stores a JSON string (same format as abstracts table). `abstract_id` tracks which abstract a document originated from (NULL for direct PDF uploads). `doi` stores bare DOI format (e.g., `10.1234/example`).

**Update `create_document()` in R/db.R (line 311):**

Add optional metadata parameters with NA defaults. Update the INSERT statement to include the new columns. The function signature becomes:

```r
create_document <- function(con, notebook_id, filename, filepath, full_text, page_count,
                            title = NA_character_, authors = NA_character_,
                            year = NA_integer_, doi = NA_character_,
                            abstract_id = NA_character_) {
  id <- uuid::UUIDgenerate()

  dbExecute(con, "
    INSERT INTO documents (id, notebook_id, filename, filepath, full_text, page_count,
                           title, authors, year, doi, abstract_id)
    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
  ", list(id, notebook_id, filename, filepath, full_text, page_count,
          title, authors, year, doi, abstract_id))

  id
}
```

All existing callers pass positional args for the original 6 params, so this is backward-compatible. The new params default to NA which DuckDB stores as NULL.

Do NOT modify `list_documents()` -- the `SELECT *` already picks up new columns automatically.
  </action>
  <verify>
1. File `migrations/008_add_document_metadata.sql` exists with 5 ALTER TABLE statements.
2. Grep for `create_document` in R/db.R confirms updated signature with title, authors, year, doi, abstract_id parameters.
3. Grep for `VALUES.*\\?.*\\?.*\\?.*\\?.*\\?.*\\?.*\\?.*\\?.*\\?.*\\?.*\\?` in R/db.R confirms 11 placeholders in the INSERT.
  </verify>
  <done>
Migration 008 exists and will add title, authors, year, doi, abstract_id columns to documents table on next app start. `create_document()` accepts optional metadata parameters that default to NA, remaining backward-compatible with all existing callers.
  </done>
</task>

<task type="auto">
  <name>Task 2: Update search notebook import to carry OpenAlex metadata</name>
  <files>R/mod_search_notebook.R</files>
  <action>
**Modify the import handler in `mod_search_notebook.R` (the `observeEvent(input$do_import, {...})` block around lines 2166-2208).**

Currently the import loop (lines 2187-2203) calls `create_document()` with only filename, filepath, full_text, page_count. Update it to also pass metadata from the abstracts row.

In the `for (i in seq_len(nrow(abstracts)))` loop, after `abs <- abstracts[i, ]`, extract metadata and pass to `create_document()`:

```r
for (i in seq_len(nrow(abstracts))) {
  abs <- abstracts[i, ]

  if (!is.na(abs$abstract) && nchar(abs$abstract) > 0) {
    # Extract DOI (may be NA)
    doc_doi <- if (!is.null(abs$doi) && !is.na(abs$doi)) abs$doi else NA_character_

    # Extract authors (already JSON string in abstracts table)
    doc_authors <- if (!is.null(abs$authors) && !is.na(abs$authors)) abs$authors else NA_character_

    # Extract year (may be NA)
    doc_year <- if (!is.null(abs$year) && !is.na(abs$year)) as.integer(abs$year) else NA_integer_

    doc_id <- create_document(
      con(), target,
      paste0(abs$title, ".txt"),
      "",
      abs$abstract,
      1,
      title = abs$title,
      authors = doc_authors,
      year = doc_year,
      doi = doc_doi,
      abstract_id = abs$id
    )

    create_chunk(con(), doc_id, "document", 0, abs$abstract, page_number = 1)
    imported <- imported + 1
  }
}
```

Key points:
- `abs$authors` is already a JSON string in the abstracts table -- pass through as-is (no re-encoding needed).
- `abs$doi` is bare format from the DOI backfill system -- pass through as-is.
- `abstract_id = abs$id` links back to the source abstract record.
- Guard each field with NA fallback since some abstracts may have NULL values for these columns.
  </action>
  <verify>
1. Grep for `abstract_id` in R/mod_search_notebook.R confirms it appears in the create_document() call.
2. Grep for `doc_doi\|doc_authors\|doc_year` in R/mod_search_notebook.R confirms metadata extraction.
3. Verify the create_document() call has `title =`, `authors =`, `year =`, `doi =`, `abstract_id =` named args.
  </verify>
  <done>
When papers are imported from search notebook to document notebook, the import workflow now carries over title, authors, year, DOI, and abstract_id from the abstracts table into the documents table. Direct PDF uploads remain unaffected (metadata columns stay NULL).
  </done>
</task>

<task type="auto">
  <name>Task 3: Add build_context_by_paper(), validate_gfm_table(), generate_lit_review_table() with DOI injection to rag.R</name>
  <files>R/rag.R</files>
  <action>
Add three new functions after `generate_research_questions()` at the end of rag.R. Follow the patterns established by `generate_conclusions_preset()` and `generate_research_questions()`.

**Function 1: `build_context_by_paper(papers_with_chunks)`**

Groups chunks under per-paper delimiters. Input: list of lists, each with `$label` (display name like "Author (Year)"), `$doc_id`, `$chunks` (data frame with content, page_number, section_hint columns). Output: single string with `=== PAPER: {label} ===` delimiters.

```r
build_context_by_paper <- function(papers_with_chunks) {
  sections <- vapply(papers_with_chunks, function(paper) {
    if (is.null(paper$chunks) || nrow(paper$chunks) == 0) {
      return(sprintf("=== PAPER: %s ===\n[No content available]", paper$label))
    }

    chunk_texts <- vapply(seq_len(nrow(paper$chunks)), function(i) {
      hint <- if (!is.na(paper$chunks$section_hint[i])) paper$chunks$section_hint[i] else "general"
      sprintf("[p.%d, %s] %s",
              paper$chunks$page_number[i],
              hint,
              paper$chunks$content[i])
    }, character(1))

    sprintf("=== PAPER: %s ===\n%s", paper$label, paste(chunk_texts, collapse = "\n\n"))
  }, character(1))

  paste(sections, collapse = "\n\n")
}
```

**Function 2: `validate_gfm_table(text)`**

Regex pipe-count validation per CONTEXT.md decision. Returns TRUE if valid GFM table, FALSE otherwise.

```r
validate_gfm_table <- function(text) {
  lines <- strsplit(text, "\n")[[1]]
  table_lines <- trimws(lines[grepl("\\|", lines)])
  table_lines <- table_lines[nchar(table_lines) > 0]

  if (length(table_lines) < 3) return(FALSE)  # header + separator + at least 1 row

  pipe_counts <- vapply(table_lines, function(l) {
    nchar(gsub("[^|]", "", l))
  }, integer(1), USE.NAMES = FALSE)

  length(unique(pipe_counts)) == 1
}
```

**Function 3: `generate_lit_review_table(con, config, notebook_id, session_id = NULL)`**

This is the main function. Follow the `generate_conclusions_preset()` structure closely. Key differences:

1. **API setup** (identical to conclusions): Extract api_key, chat_model. Guard empty key.

2. **Get documents with metadata:**
```r
docs <- dbGetQuery(con, "
  SELECT id, filename, title, authors, year, doi
  FROM documents WHERE notebook_id = ?
  ORDER BY year DESC NULLS LAST, filename
", list(notebook_id))
```
If `nrow(docs) == 0`, return "No documents found in this notebook."

3. **Store paper count:**
```r
paper_count <- nrow(docs)
```

4. **Build paper labels with metadata fallback:**
For each document, create a display label. If `title`/`authors`/`year` exist (imported from search notebook), parse authors JSON and format as "LastName et al. (Year)". If metadata is NULL (direct PDF upload), use `filename` stripped of extension. Store labels in a list for DOI injection later.

```r
paper_labels <- lapply(seq_len(nrow(docs)), function(i) {
  doc <- docs[i, ]
  if (!is.na(doc$title) && !is.na(doc$authors) && !is.na(doc$year)) {
    authors_parsed <- tryCatch(jsonlite::fromJSON(doc$authors), error = function(e) NULL)
    if (!is.null(authors_parsed) && length(authors_parsed) > 0) {
      # Extract last names - authors stored as JSON array of objects with display_name
      if (is.data.frame(authors_parsed) && "display_name" %in% names(authors_parsed)) {
        last_names <- vapply(authors_parsed$display_name, function(a) {
          parts <- strsplit(trimws(a), "\\s+")[[1]]
          parts[length(parts)]
        }, character(1))
      } else if (is.character(authors_parsed)) {
        last_names <- vapply(authors_parsed, function(a) {
          parts <- strsplit(trimws(a), "\\s+")[[1]]
          parts[length(parts)]
        }, character(1))
      } else {
        last_names <- "Unknown"
      }

      author_str <- if (length(last_names) > 2) {
        paste0(last_names[1], " et al.")
      } else if (length(last_names) == 2) {
        paste0(last_names[1], " & ", last_names[2])
      } else {
        last_names[1]
      }
      label <- sprintf("%s (%d)", author_str, doc$year)
    } else {
      label <- sprintf("Unknown (%s)", if (!is.na(doc$year)) as.character(doc$year) else "n.d.")
    }
  } else {
    label <- tools::file_path_sans_ext(doc$filename)
  }
  list(label = label, doi = doc$doi, doc_id = doc$id)
})
```

5. **Section-aware chunk retrieval with dynamic token budget:**

CRITICAL FIX: The `lapply` for chunk retrieval MUST be INSIDE the `repeat` loop body so re-querying actually occurs when `chunks_per_paper` is reduced.

```r
max_context_tokens <- 80000L
chunks_per_paper <- 7L

repeat {
  # Re-query chunks with current chunks_per_paper limit
  papers_data <- lapply(seq_len(nrow(docs)), function(i) {
    doc <- docs[i, ]

    # Try section-filtered first
    section_chunks <- dbGetQuery(con, "
      SELECT chunk_index, content, page_number, section_hint
      FROM chunks
      WHERE source_id = ? AND section_hint IN ('methods', 'methodology', 'results', 'limitations', 'discussion', 'conclusion')
      ORDER BY chunk_index
      LIMIT ?
    ", list(doc$id, chunks_per_paper))

    if (nrow(section_chunks) < 2) {
      # Fallback: distributed sampling
      all_chunks <- dbGetQuery(con, "
        SELECT chunk_index, content, page_number,
               COALESCE(section_hint, 'general') as section_hint
        FROM chunks WHERE source_id = ?
        ORDER BY chunk_index
      ", list(doc$id))

      if (nrow(all_chunks) > chunks_per_paper) {
        n <- nrow(all_chunks)
        indices <- unique(c(1, 2, ceiling(n/2), n-1, n))
        indices <- indices[indices >= 1 & indices <= n]
        indices <- sort(head(indices, chunks_per_paper))
        all_chunks <- all_chunks[indices, ]
      }
      section_chunks <- all_chunks
    }

    list(label = paper_labels[[i]]$label, doc_id = doc$id, chunks = section_chunks)
  })

  # Estimate tokens
  total_est <- sum(vapply(papers_data, function(p) {
    if (is.null(p$chunks) || nrow(p$chunks) == 0) return(0)
    ceiling(nchar(paste(p$chunks$content, collapse = " ")) / 4)
  }, numeric(1)))

  if (total_est <= max_context_tokens || chunks_per_paper <= 2L) break
  chunks_per_paper <- chunks_per_paper - 1L
}
```

6. **Token budget hard check after loop:**
```r
context <- build_context_by_paper(papers_data)
est_tokens <- ceiling(nchar(context) / 4)
if (est_tokens > max_context_tokens) {
  return(sprintf(
    "The combined document content (~%dk tokens) exceeds the analysis limit (%dk). Consider splitting documents across multiple notebooks or reducing the number of papers.",
    round(est_tokens / 1000), round(max_context_tokens / 1000)
  ))
}
```

7. **System prompt:**
```r
system_prompt <- paste0(
  "You are a systematic review assistant. Generate a literature review comparison table in GFM (GitHub Flavored Markdown) pipe table format.\n\n",
  "COLUMNS (exactly these, in this order):\n",
  "| Author/Year | Methodology | Sample | Key Findings | Limitations |\n\n",
  "RULES:\n",
  "- One row per paper, ordered by most recent first\n",
  "- Author/Year: Use the exact label from the paper delimiter (e.g., 'Smith et al. (2023)')\n",
  "- Each cell: brief phrases (2-5 words), NOT full sentences\n",
  "- Key Findings: single consolidated statement per paper, no bullet points\n",
  "- For N/A columns: use contextual notes (e.g., 'Theoretical framework', 'Systematic review') instead of literal 'N/A'\n",
  "- Output ONLY the markdown table. No introduction, no summary, no notes before or after the table.\n",
  "- Every line of the table must have exactly 6 pipe characters (| col1 | col2 | col3 | col4 | col5 |)"
)
```

8. **User prompt:**
```r
user_prompt <- sprintf(
  "===== DOCUMENTS (%d papers) =====\n%s\n===== END =====\n\nGenerate the literature review comparison table.",
  paper_count, context
)
```

9. **LLM call + cost logging** (same pattern as conclusions):
```r
messages <- format_chat_messages(system_prompt, user_prompt)
result <- chat_completion(api_key, chat_model, messages)

if (!is.null(session_id) && !is.null(result$usage)) {
  cost <- estimate_cost(chat_model,
                        result$usage$prompt_tokens %||% 0,
                        result$usage$completion_tokens %||% 0)
  log_cost(con, "lit_review_table", chat_model,
           result$usage$prompt_tokens %||% 0,
           result$usage$completion_tokens %||% 0,
           result$usage$total_tokens %||% 0,
           cost, session_id)
}
```

10. **Validate + DOI injection:**
```r
response <- result$content

# Strip any markdown code fences the LLM might wrap the table in
response <- gsub("^```[a-z]*\\s*\n", "", response)
response <- gsub("\n```\\s*$", "", response)
response <- trimws(response)

if (!validate_gfm_table(response)) {
  return("Table appears malformed. Please try again by clicking the Lit Review button.")
}

# DOI injection: replace Author/Year text with markdown links where DOI is available
for (pl in paper_labels) {
  if (!is.na(pl$doi) && nchar(pl$doi) > 0) {
    # Use fixed string matching (labels don't need regex)
    doi_link <- sprintf("[%s](https://doi.org/%s)", pl$label, pl$doi)
    response <- gsub(pl$label, doi_link, response, fixed = TRUE)
  }
}

# Check for missing papers and add note
lines <- strsplit(response, "\n")[[1]]
data_rows <- lines[!grepl("^\\s*\\|[-:| ]+\\|\\s*$", lines)]  # exclude separator row
data_rows <- data_rows[grepl("\\|", data_rows)]
# Subtract 1 for header row
actual_rows <- length(data_rows) - 1
if (actual_rows < paper_count && actual_rows > 0) {
  missing <- paper_count - actual_rows
  response <- paste0(response, sprintf("\n\n*Note: %d paper(s) could not be analyzed and are not shown.*", missing))
}

response
```

Wrap the entire function body (from step 1 onwards) in a `tryCatch` that returns an error string on failure:
```r
tryCatch({
  # ... all the above ...
}, error = function(e) {
  sprintf("Error generating literature review table: %s", e$message)
})
```
  </action>
  <verify>
1. Grep for `build_context_by_paper` in R/rag.R -- function definition exists.
2. Grep for `validate_gfm_table` in R/rag.R -- function definition exists.
3. Grep for `generate_lit_review_table` in R/rag.R -- function definition exists.
4. Grep for `lit_review_table` in R/rag.R -- cost logging category present.
5. Grep for `chunks_per_paper <- 7L` inside the repeat loop body -- confirms dynamic budget loop is correct (lapply INSIDE repeat).
6. Grep for `doi_link` in R/rag.R -- DOI injection post-processing present.
7. Grep for `Table appears malformed` in R/rag.R -- plain text error message (NOT a retry button).
  </verify>
  <done>
Three new functions exist in rag.R: `build_context_by_paper()` groups chunks under paper delimiters, `validate_gfm_table()` checks pipe-count consistency, `generate_lit_review_table()` orchestrates section-aware retrieval with dynamic token budgeting (lapply inside repeat loop), single LLM call, GFM validation, and server-side DOI injection. Cost logged under "lit_review_table". Malformed output returns plain text error message.
  </done>
</task>

<task type="auto">
  <name>Task 4: Wire Lit Review button, handler, disclaimer, and HTML post-processing in mod_document_notebook.R</name>
  <files>R/mod_document_notebook.R</files>
  <action>
**Four changes to mod_document_notebook.R:**

1. **Add Lit Review button to preset bar (around line 61, after the Conclusions button and before Slides):**
```r
actionButton(ns("btn_lit_review"), "Lit Review",
             class = "btn-sm btn-outline-primary",
             icon = icon("table-cells"))
```
Insert this inside the `btn-group` div, between the Conclusions and Slides buttons.

2. **Update disclaimer check (line 600):**
Change:
```r
is_synthesis <- !is.null(msg$preset_type) && msg$preset_type %in% c("conclusions", "research_questions")
```
To:
```r
is_synthesis <- !is.null(msg$preset_type) && msg$preset_type %in% c("conclusions", "research_questions", "lit_review")
```

3. **Add HTML post-processing for lit_review messages in the renderer (around line 613):**

Currently the renderer does:
```r
HTML(commonmark::markdown_html(msg$content, extensions = TRUE))
```

Replace this single line with conditional logic that wraps lit_review tables in a scrollable div:
```r
{
  rendered_html <- commonmark::markdown_html(msg$content, extensions = TRUE)
  if (!is.null(msg$preset_type) && identical(msg$preset_type, "lit_review")) {
    # Wrap table in scrollable container with frozen first column support
    rendered_html <- gsub(
      "<table>",
      '<div class="lit-review-scroll"><table class="table table-striped table-bordered">',
      rendered_html)
    rendered_html <- gsub("</table>", "</table></div>", rendered_html)
  }
  HTML(rendered_html)
}
```

This wraps ONLY lit_review message tables in the scroll container. Regular chat tables keep existing CSS.

4. **Add observeEvent handler (after the conclusions handler around line 755, BEFORE the slides module block):**

```r
# Literature Review Table preset handler
observeEvent(input$btn_lit_review, {
  req(!is_processing())
  req(has_api_key())

  # Guard: RAG must be available
  if (!isTRUE(rag_available())) {
    showNotification("Synthesis unavailable - re-index this notebook first.", type = "warning")
    return()
  }

  # Warning toast for large notebooks (20+ papers)
  nb_id <- notebook_id()
  doc_count <- tryCatch(nrow(list_documents(con(), nb_id)), error = function(e) 0L)
  if (doc_count >= 20L) {
    showNotification(
      sprintf("Analyzing %d papers - output quality may degrade with large collections.", doc_count),
      type = "warning", duration = 8
    )
  }

  is_processing(TRUE)

  msgs <- messages()
  msgs <- c(msgs, list(list(
    role = "user",
    content = "Generate: Literature Review Table",
    timestamp = Sys.time(),
    preset_type = "lit_review"
  )))
  messages(msgs)

  cfg <- config()

  response <- tryCatch({
    generate_lit_review_table(con(), cfg, nb_id, session_id = session$token)
  }, error = function(e) {
    sprintf("Error: %s", e$message)
  })

  msgs <- c(msgs, list(list(
    role = "assistant",
    content = response,
    timestamp = Sys.time(),
    preset_type = "lit_review"
  )))
  messages(msgs)
  is_processing(FALSE)
})
```

Key details:
- RAG availability guard (same pattern as conclusions but explicit since doc notebook uses static buttons)
- Warning toast at 20+ papers per CONTEXT.md decision
- `preset_type = "lit_review"` on both user and assistant messages (triggers disclaimer + scroll wrapper)
  </action>
  <verify>
1. Grep for `btn_lit_review` in R/mod_document_notebook.R -- appears in UI (actionButton) and handler (observeEvent).
2. Grep for `generate_lit_review_table` in R/mod_document_notebook.R -- called in handler.
3. Grep for `lit_review` in R/mod_document_notebook.R -- appears in disclaimer check, preset_type assignments, and HTML post-processing.
4. Grep for `lit-review-scroll` in R/mod_document_notebook.R -- scroll wrapper injection present.
5. Verify the disclaimer check line has all three types: `c("conclusions", "research_questions", "lit_review")`.
  </verify>
  <done>
Document notebook has a "Lit Review" button in the preset panel. Handler calls `generate_lit_review_table()`, sets `preset_type = "lit_review"`, shows 20+ paper warning toast. Disclaimer check includes "lit_review". Message renderer wraps lit_review table HTML in scrollable div with Bootstrap table classes.
  </done>
</task>

<task type="auto">
  <name>Task 5: Add CSS for scrollable table with frozen first column in app.R</name>
  <files>app.R</files>
  <action>
**Add CSS rules to the `tags$style(HTML(...))` block in app.R (after the existing `.chat-markdown` rules ending around line 96, before the closing `"))`).**

Add these rules. Note: NO sticky column headers per CONTEXT.md decision (vertical sticky was dropped because the chat panel is the scroll ancestor, not the table wrapper). Only frozen first column (horizontal sticky) is implemented.

```css
/* Literature review table: horizontal scroll + frozen first column */
.lit-review-scroll {
  overflow-x: auto;
  max-width: 100%;
  border: 1px solid #dee2e6;
  border-radius: 0.25rem;
  margin: 0.5em 0;
}
.lit-review-scroll table {
  min-width: 900px;
  border-collapse: separate;
  border-spacing: 0;
  margin: 0;
}
.lit-review-scroll th:first-child,
.lit-review-scroll td:first-child {
  position: sticky;
  left: 0;
  z-index: 1;
  background-color: #f1f3f5;
  border-right: 2px solid #adb5bd;
  min-width: 140px;
  max-width: 200px;
}
.lit-review-scroll th:first-child {
  z-index: 2;
  background-color: #e9ecef;
}
.lit-review-scroll th {
  white-space: nowrap;
}
.lit-review-scroll td {
  min-width: 120px;
  max-width: 250px;
}
/* Dark theme support for frozen column */
[data-bs-theme='dark'] .lit-review-scroll {
  border-color: #495057;
}
[data-bs-theme='dark'] .lit-review-scroll th:first-child,
[data-bs-theme='dark'] .lit-review-scroll td:first-child {
  background-color: #343a40;
  border-right-color: #6c757d;
}
[data-bs-theme='dark'] .lit-review-scroll th:first-child {
  background-color: #2b3035;
}
```

Key CSS points:
- NO `position: sticky; top: 0;` on thead th -- sticky column headers are DROPPED per CONTEXT.md
- `min-width: 900px` on the table forces horizontal scroll in the chat panel
- First column gets `position: sticky; left: 0;` for frozen behavior
- Dark theme variants use `[data-bs-theme='dark']` selector (Bootstrap 5 / bslib convention)
- `border-collapse: separate` is required for sticky positioning to work
- `width: auto` is NOT set on the table because the `min-width` override is sufficient, and `width: 100%` from `.chat-markdown table` does not apply since the lit-review-scroll wrapper's table gets its own min-width
  </action>
  <verify>
1. Grep for `lit-review-scroll` in app.R -- CSS class defined.
2. Grep for `position: sticky` in app.R -- appears ONLY with `left: 0` (for frozen column), NOT with `top: 0` (no sticky headers).
3. Grep for `data-bs-theme` in app.R -- dark theme variants present.
4. Verify no `thead th.*position.*sticky.*top` pattern exists in the lit-review-scroll section (sticky headers were dropped).
  </verify>
  <done>
CSS in app.R provides: scrollable container with `overflow-x: auto`, frozen first column via `position: sticky; left: 0`, min-width forcing horizontal scroll, dark theme support, and NO sticky column headers (dropped per CONTEXT.md). Table renders with Bootstrap table-striped and table-bordered classes (injected in Task 4 HTML post-processing).
  </done>
</task>

</tasks>

<verification>
1. `grep -rn "generate_lit_review_table" R/` -- function defined in rag.R, called in mod_document_notebook.R
2. `grep -rn "build_context_by_paper" R/rag.R` -- function exists
3. `grep -rn "validate_gfm_table" R/rag.R` -- function exists
4. `grep -rn "btn_lit_review" R/mod_document_notebook.R` -- button in UI and handler
5. `grep -rn "lit_review" R/mod_document_notebook.R` -- disclaimer check, preset_type, HTML wrapper
6. `grep -rn "lit-review-scroll" app.R R/mod_document_notebook.R` -- CSS defined and wrapper injected
7. `grep -rn "abstract_id" R/db.R R/mod_search_notebook.R migrations/` -- migration, create_document, import workflow
8. `cat migrations/008_add_document_metadata.sql` -- migration file exists with 5 ALTER statements
9. `grep -rn "doi_link" R/rag.R` -- DOI injection post-processing present
10. Verify NO `position: sticky.*top` in app.R lit-review-scroll section (sticky headers dropped)
11. `grep -rn "format_chat_as_markdown\|format_chat_as_html" R/utils_export.R` -- these pass msg$content through as raw markdown; GFM tables export correctly since content contains the pipe table text
</verification>

<success_criteria>
- Migration 008 adds title, authors, year, doi, abstract_id to documents table
- create_document() accepts optional metadata parameters, backward-compatible
- Search notebook import carries OpenAlex metadata (title, authors, year, doi, abstract_id) to document records
- build_context_by_paper() groups chunks under paper delimiters using metadata-derived labels
- validate_gfm_table() checks pipe-count consistency
- generate_lit_review_table() uses section-aware SQL with dynamic token budget (lapply INSIDE repeat loop), single LLM call, GFM validation, and server-side DOI injection
- Malformed output returns plain text error message: "Table appears malformed. Please try again by clicking the Lit Review button." (no retry button)
- Lit Review button visible in document notebook preset panel
- Click triggers LLM call and renders GFM table in chat with Bootstrap styling
- AI-generated content disclaimer appears on lit_review output
- Table has horizontal scroll with frozen first column, NO sticky headers
- Dark theme CSS variants present
- Cost logged under "lit_review_table" category
- DOI links injected for documents with DOI metadata; plain text Author/Year for documents without
- Export functions (format_chat_as_markdown, format_chat_as_html) handle lit_review messages correctly (they pass raw markdown content which includes GFM tables)
</success_criteria>

<output>
After completion, create `.planning/phases/28-literature-review-table/28-01-SUMMARY.md`
</output>
