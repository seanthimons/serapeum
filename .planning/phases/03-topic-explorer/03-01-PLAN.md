---
phase: 03-topic-explorer
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - R/api_openalex.R
  - R/db.R
autonomous: true

must_haves:
  truths:
    - "Topic data can be fetched from OpenAlex API with pagination"
    - "Topics are cached in DuckDB with bulk insert"
    - "Cache staleness is tracked via quality_cache_meta (30-day TTL)"
    - "Hierarchy choices can be queried by level (domain/field/subfield/topic)"
  artifacts:
    - path: "R/api_openalex.R"
      provides: "fetch_all_topics(), parse_topic() functions"
      exports: ["fetch_all_topics", "parse_topic"]
    - path: "R/db.R"
      provides: "cache_topics(), get_cached_topics(), get_hierarchy_choices() functions"
      exports: ["cache_topics", "get_cached_topics", "get_hierarchy_choices"]
  key_links:
    - from: "R/api_openalex.R"
      to: "OpenAlex /topics endpoint"
      via: "build_openalex_request with pagination"
      pattern: "build_openalex_request.*topics"
    - from: "R/db.R"
      to: "topics table"
      via: "dbWriteTable bulk insert and SQL queries"
      pattern: "dbWriteTable.*topics"
    - from: "R/db.R"
      to: "quality_cache_meta table"
      via: "update_quality_cache_meta for freshness tracking"
      pattern: "update_quality_cache_meta.*openalex_topics"
---

<objective>
Add OpenAlex Topics API integration and DuckDB caching functions for the topic taxonomy.

Purpose: Provides the data layer that the topic explorer UI module (Plan 03-02) will consume. Fetches ~4,500 topics from OpenAlex with offset-based pagination and caches them locally for fast hierarchy browsing.

Output: Two files modified with new functions -- API fetching in api_openalex.R and caching/querying in db.R.
</objective>

<execution_context>
@C:/Users/sxthi/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/sxthi/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-topic-explorer/03-RESEARCH.md
@R/api_openalex.R
@R/db.R
@migrations/002_create_topics_table.sql
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add topic fetching functions to api_openalex.R</name>
  <files>R/api_openalex.R</files>
  <action>
Add two functions to the end of R/api_openalex.R:

1. `parse_topic(topic)` -- Parse a single OpenAlex topic object into a flat list:
   - Extract topic_id by stripping "https://openalex.org/" prefix from `topic$id`
   - Extract display_name, description, works_count directly
   - Convert keywords list to JSON string via `jsonlite::toJSON(topic$keywords, auto_unbox = FALSE)`, default "[]" if NULL/empty
   - Flatten hierarchy: domain_id/domain_name from `topic$domain`, field_id/field_name from `topic$field`, subfield_id/subfield_name from `topic$subfield` -- strip URL prefix from IDs, use NA_character_ if NULL
   - Return named list with all 11 fields matching the topics table schema

2. `fetch_all_topics(email, api_key, per_page = 100)` -- Fetch all ~4,500 topics with pagination:
   - Validate api_key is present and non-empty, stop() with message directing to Settings if missing
   - Loop pages starting at page=1 using `build_openalex_request("topics", email, api_key)` (already exists in this file)
   - Add query params: per_page, page, select = "id,display_name,description,keywords,works_count,domain,field,subfield"
   - Parse each page's results via `parse_topic()`, accumulate in list
   - Break when `length(body$results) == 0` OR `total_fetched >= body$meta$count`
   - Add `Sys.sleep(0.1)` between pages for rate limiting
   - Use `message()` for progress logging (e.g., "[openalex] Fetching topics page N...")
   - Convert final list to data frame via `do.call(rbind, lapply(all_topics, as.data.frame, stringsAsFactors = FALSE))`
   - Wrap req_perform in tryCatch, re-throw with clear error message on failure

Follow existing code style in api_openalex.R: roxygen comments, use `%||%` for NULL defaults, consistent with parse_openalex_work pattern.
  </action>
  <verify>
Open R and source the file without errors:
```
"C:\Program Files\R\R-4.5.1\bin\Rscript.exe" -e "source('R/api_openalex.R'); cat('parse_topic exists:', exists('parse_topic'), '\n'); cat('fetch_all_topics exists:', exists('fetch_all_topics'), '\n')"
```
Both functions should exist and the file should source without syntax errors.
  </verify>
  <done>
  - parse_topic() converts OpenAlex topic JSON object to flat list with 11 fields matching topics table schema
  - fetch_all_topics() fetches all topics via paginated API calls using existing build_openalex_request()
  - API key validation stops with clear error if key missing
  - Rate limiting (0.1s sleep) between pages
  </done>
</task>

<task type="auto">
  <name>Task 2: Add topic caching and hierarchy query functions to db.R</name>
  <files>R/db.R</files>
  <action>
Add three functions to R/db.R (after the existing quality cache functions, near line 920+):

1. `cache_topics(con, topics_df)` -- Bulk insert topics into DuckDB:
   - DELETE FROM topics first (full refresh strategy)
   - Prepare clean data frame with explicit type coercion: as.character() for all VARCHAR columns, as.integer() for works_count, format(Sys.time(), "%Y-%m-%d %H:%M:%S") for updated_at
   - Use `dbWriteTable(con, "topics", topics_clean, append = TRUE)` for bulk insert (NOT row-by-row)
   - Call `update_quality_cache_meta(con, "openalex_topics", nrow(topics_clean))` to track freshness
   - Return nrow(topics_clean) for logging
   - Follow the exact pattern from `cache_predatory_publishers()` (lines ~864-886 in db.R)

2. `get_cached_topics(con, max_age_days = 30)` -- Return cached topics or empty df if stale:
   - Call `get_quality_cache_meta(con, "openalex_topics")` to check freshness
   - If NULL (no cache), return empty data.frame() with message
   - If age > max_age_days, return empty data.frame() with message
   - Otherwise, return `dbGetQuery(con, "SELECT * FROM topics ORDER BY domain_name, field_name, subfield_name, display_name")`

3. `get_hierarchy_choices(con, level = "domain", parent_id = NULL)` -- Return named character vector for selectInput:
   - level="domain": SELECT DISTINCT domain_id, domain_name FROM topics WHERE domain_id IS NOT NULL ORDER BY domain_name. Return setNames(domain_id, domain_name).
   - level="field": Filter by parent_id (domain_id). SELECT DISTINCT field_id, field_name FROM topics WHERE domain_id = ? AND field_id IS NOT NULL ORDER BY field_name. Return empty character(0) if parent_id is NULL.
   - level="subfield": Filter by parent_id (field_id). SELECT DISTINCT subfield_id, subfield_name ... WHERE field_id = ? AND subfield_id IS NOT NULL. Return empty if no parent.
   - level="topic": Filter by parent_id (subfield_id). SELECT topic_id, display_name, works_count ... WHERE subfield_id = ?. Format labels as "Name (N works)" using sprintf and format(works_count, big.mark = ","). Return setNames(topic_id, labels).
   - Use parameterized queries (list(parent_id)) for all filtered queries.

Add roxygen comments matching the existing style in db.R.
  </action>
  <verify>
Source the file and check functions exist:
```
"C:\Program Files\R\R-4.5.1\bin\Rscript.exe" -e "source('R/db.R'); cat('cache_topics:', exists('cache_topics'), '\n'); cat('get_cached_topics:', exists('get_cached_topics'), '\n'); cat('get_hierarchy_choices:', exists('get_hierarchy_choices'), '\n')"
```
All three functions should exist. File should source without errors.
  </verify>
  <done>
  - cache_topics() bulk inserts topic data frame into DuckDB topics table and updates quality_cache_meta
  - get_cached_topics() returns topics if cache fresh (< 30 days), empty data.frame if stale/missing
  - get_hierarchy_choices() returns named character vectors suitable for Shiny selectInput at each hierarchy level
  - All functions use parameterized queries and follow existing db.R conventions
  </done>
</task>

</tasks>

<verification>
1. Both R/api_openalex.R and R/db.R source without errors
2. All 5 new functions exist: parse_topic, fetch_all_topics, cache_topics, get_cached_topics, get_hierarchy_choices
3. No existing functions broken (app still starts)
</verification>

<success_criteria>
- OpenAlex topic fetching functions ready for use by topic explorer module
- DuckDB caching functions ready with cache metadata tracking
- Hierarchy query function returns selectInput-compatible choices at all 4 levels
- No new R package dependencies required
</success_criteria>

<output>
After completion, create `.planning/phases/03-topic-explorer/03-01-SUMMARY.md`
</output>
